{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "b22ac4cc-b06c-4e72-9268-eb0fc92ba8e4",
      "cell_type": "code",
      "source": "\nimport torch\nimport numpy as np\nimport random\n\n# Set random seed for reproducibility\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom matplotlib.widgets import Slider  # Add this import\nimport numpy as np\nfrom diffusion_models3d import Transformer, AbsorbingDiffusion, Block, CausalSelfAttention\nfrom sampler_utils import retrieve_autoencoder_components_state_dicts, latent_ids_to_onehot3d, get_latent_loaders\nfrom models3d import VQAutoEncoder, Generator\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, fixed\n# from visualization_utils import MinecraftVisualizer\nfrom data_utils import MinecraftVisualizer, get_minecraft_dataloaders, BlockConverter, MinecraftDataset\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\nfrom concurrent.futures import ThreadPoolExecutor\nfrom PIL import Image\nimport torch.distributions as dists\nfrom tqdm import tqdm\nimport gc\nfrom scipy.stats import entropy\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.colors as mcolors\n\nget_ipython().run_line_magic('matplotlib', 'widget')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7a3663c4-c07d-4d4b-92d2-7aee35f9b677",
      "cell_type": "code",
      "source": "blocks_to_cols = {\n            0: (0.5, 0.25, 0.0),    # light brown\n            10: 'black', # bedrock\n            29: \"#006400\", # cacutus\n            38: \"#B8860B\",  # clay\n            60: \"brown\",  # dirt\n            92: \"gold\",  # gold ore\n            93: \"green\",  # grass\n            115: \"brown\",  # ladder...?\n            119: (.02, .28, .16, 0.8),  # transparent forest green (RGBA) for leaves\n            120: (.02, .28, .16, 0.8),  # leaves2\n            194: \"yellow\",  # sand\n            217: \"gray\",  # stone\n            240: (0.0, 0.0, 1.0, 0.4),  # water\n            227: (0.0, 1.0, 0.0, .3), # tall grass\n            237: (0.33, 0.7, 0.33, 0.3), # vine\n            40: \"#2F4F4F\",  # coal ore\n            62: \"#228B22\",  # double plant\n            108: \"#BEBEBE\",  # iron ore\n            131: \"saddlebrown\",  # log1\n            132: \"saddlebrown\",  #log2\n            95: \"lightgray\",  # gravel\n            243: \"wheat\",  # wheat. lmao\n            197: \"limegreen\",  # sapling\n            166: \"orange\",  #pumpkin\n            167: \"#FF8C00\",  # pumpkin stem\n            184: \"#FFA07A\",  # red flower\n            195: \"tan\",  # sandstone\n            250: \"white\",  #wool \n            251: \"gold\",   #yellow flower\n        }\n\n\n\n\ndef draw_latent_cuboid(fig, latent_coords, size=4):\n    \"\"\"\n    Draw a transparent cuboid around the specified latent coordinates.\n    \n    Args:\n        fig: matplotlib figure to draw on\n        latent_coords: list of tuples, each containing (d,h,w) coordinates\n        size: size of each latent cell in final space (default 4 for 6->24 upscaling)\n    \"\"\"\n    def cuboid_data(o, sizes):\n        l, w, h = sizes\n        x = [[o[0], o[0] + l, o[0] + l, o[0], o[0]],  \n             [o[0], o[0] + l, o[0] + l, o[0], o[0]],  \n             [o[0], o[0] + l, o[0] + l, o[0], o[0]],  \n             [o[0], o[0] + l, o[0] + l, o[0], o[0]]]  \n        y = [[o[1], o[1], o[1] + w, o[1] + w, o[1]],  \n             [o[1], o[1], o[1] + w, o[1] + w, o[1]],  \n             [o[1], o[1], o[1], o[1], o[1]],          \n             [o[1] + w, o[1] + w, o[1] + w, o[1] + w, o[1] + w]]\n        z = [[o[2], o[2], o[2], o[2], o[2]],          \n             [o[2] + h, o[2] + h, o[2] + h, o[2] + h, o[2] + h],\n             [o[2], o[2], o[2] + h, o[2] + h, o[2]],  \n             [o[2], o[2], o[2] + h, o[2] + h, o[2]]]  \n        return np.array(x), np.array(y), np.array(z)\n\n    ax = fig.gca()\n    \n    # Convert coordinates to numpy array for easier manipulation\n    coords = np.array(latent_coords)\n    \n    # Find min and max for each dimension\n    d_min, h_min, w_min = coords.min(axis=0)\n    d_max, h_max, w_max = coords.max(axis=0)\n    \n    # Calculate origin and sizes\n    origin = np.array([abs(5 - d_max)*size, w_min*size, h_min*size])\n    sizes = (\n        abs(d_max - d_min + 1) * size,  # length\n        (w_max - w_min + 1) * size,     # width\n        (h_max - h_min + 1) * size      # height\n    )\n    \n    # Create and draw single cuboid\n    X, Y, Z = cuboid_data(origin, sizes)\n    ax.plot_surface(X, Y, Z, color='red', alpha=0.1)\n    \n    # Plot edges\n    for i in range(4):\n        ax.plot(X[i], Y[i], Z[i], color='red', linewidth=1)\n    for i in range(4):\n        ax.plot([X[0][i], X[1][i]], [Y[0][i], Y[1][i]], [Z[0][i], Z[1][i]], \n               color='red', linewidth=2)\n    \n    return fig\n\ndef visualize_chunk(voxels, figsize=(10, 10), elev=20, azim=45, highlight_latents=None):\n    \"\"\"\n    Optimized version of the 3D visualization of a Minecraft chunk.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    # print(\"voxels: \", voxels)\n    # Convert one-hot to block IDs if needed\n    if isinstance(voxels, torch.Tensor):\n        if voxels.dim() == 4:  # One-hot encoded [C,H,W,D]\n            voxels = voxels.detach().cpu()\n            voxels = torch.argmax(voxels, dim=0).numpy()\n        else:\n            voxels = voxels.detach().cpu().numpy()\n    # print(\"voxels: \", voxels)\n    # Apply the same transformations as original\n    voxels = voxels.transpose(2, 0, 1) # Moves axes from [D,H,W] to [W,D,H]\n    voxels = np.rot90(voxels, 1, (0, 1))  # Rotate 90 degrees around height axis\n    # print([block_id for block_id in np.unique(voxels) if block_id not in blocks_to_cols])\n    # Create figure and 3D axis\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111, projection='3d')\n    # depth, height, width = voxels.shape\n    # # Set the aspect ratio to match the data dimensions\n    # ax.set_box_aspect((depth, height, width))\n    # Generate a single boolean mask for each block type\n    # print(\"unique: \", np.unique(voxels))\n    block_masks = {int(block_id): (voxels == block_id) for block_id in np.unique(voxels) if int(block_id) in blocks_to_cols}\n    # print(\"masks: \", block_masks)\n    # Plot all block types with their respective colors\n    for block_id, mask in block_masks.items():\n        ax.voxels(mask, facecolors=blocks_to_cols[int(block_id)])\n    \n    # Plot remaining blocks in red with black edges\n    # other_vox = (voxels != 5) & (voxels != -1) & (~np.any(np.stack(list(block_masks.values())), axis=0))\n    other_vox = (voxels == 5) | (~np.isin(voxels, list(blocks_to_cols.keys()))) # Directly check for air blocks\n    ax.voxels(other_vox, edgecolor=\"k\", facecolors=(1, 0, 0, 0.5))\n    \n    # Set default view angle\n    ax.view_init(elev=elev, azim=azim)\n\n    if highlight_latents is not None:\n        fig = draw_latent_cuboid(fig, highlight_latents)\n    \n    return fig\n\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "176ce1f5-ff89-42d4-8b0e-b3c2806be015",
      "cell_type": "code",
      "source": "# ## Block Converter: Converts between block IDs and indices, needed for visualization\nblock_converter = BlockConverter.load_mappings('block_mappings.pt')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4535aafa-0e1c-4f50-897c-080e26d43971",
      "cell_type": "code",
      "source": "# # Minecraft Chunks Dataset\n\n\nfrom torch.utils.data import DataLoader, random_split, Dataset\n\nclass MinecraftDataset(Dataset):\n    def __init__(self, data_path, converter):\n        # Load data and convert to int16 to save memory\n        self.chunks = torch.from_numpy(np.load(data_path)).to(torch.int16)\n        \n        # Load pre-saved mappings\n        self.converter = converter\n        self.num_block_types = len(self.converter.block_to_index)\n        \n        # Convert blocks to indices once at initialization\n        for old_block, new_idx in self.converter.block_to_index.items():\n            self.chunks[self.chunks == old_block] = new_idx\n            \n        # Store air block index\n        self.air_idx = self.converter.block_to_index[5]\n        self.target_size = 24\n\n        # Pad if needed\n        pad_size = self.target_size - self.chunks.size(-1)\n        if pad_size > 0:\n            self.chunks = F.pad(self.chunks, \n                              (0, pad_size, 0, pad_size, 0, pad_size), \n                              value=self.air_idx)\n\n        # Convert to one-hot [N, C, H, W, D]\n        self.processed_chunks = F.one_hot(\n            self.chunks.long(), \n            num_classes=self.num_block_types\n        ).permute(0, 4, 1, 2, 3).float()\n        \n        # Free up memory by deleting original chunks\n        del self.chunks\n        \n        print(f\"Loaded {len(self.processed_chunks)} chunks of size {self.processed_chunks.shape[1:]}\")\n        print(f\"Number of unique block types: {self.num_block_types}\")\n\n    def __getitem__(self, idx):\n        return self.processed_chunks[idx]\n\n    def convert_to_original_blocks(self, data):\n        \"\"\"Convert from indices back to original block IDs\"\"\"\n        return self.converter.convert_to_original_blocks(data)\n\n    def __len__(self):\n        return len(self.processed_chunks)\n\n\n\ndef get_minecraft_dataloader(data_path, converter, batch_size=32, num_workers=0):\n    \"\"\"\n    Creates a single dataloader for exploring the entire Minecraft chunks dataset.\n    \"\"\"\n    # Create dataset\n    dataset = MinecraftDataset(data_path, converter)\n    \n    # Create dataloader with memory pinning\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False,  # No need to shuffle for exploration\n        num_workers=num_workers,\n        pin_memory=True,\n    )\n\n\n    \n    print(f\"\\nDataloader details:\")\n    print(f\"Total samples: {len(dataset)}\")\n    print(f\"Batch size: {batch_size}\")\n    print(f\"Number of batches: {len(dataloader)}\")\n    \n    return dataloader\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1fd91864-a565-456e-9cd9-36c1d502802a",
      "cell_type": "code",
      "source": "# # Load VQGAN Model\n\n\nimport os\nfrom log_utils import log, load_stats, load_model\nimport copy\nfrom hyperparams import HparamsVQGAN\n\n# Loads hparams from hparams.json file in saved model directory\ndef load_hparams_from_json(log_dir):\n    import json\n    import os\n    json_path = os.path.join(log_dir, 'hparams.json')\n    \n    if not os.path.exists(json_path):\n        raise FileNotFoundError(f\"No hparams.json file found in {log_dir}\")\n    \n    with open(json_path, 'r') as f:\n        hparams = json.load(f)\n\n    return hparams\n\n# turns loaded hparams json into propery hyperparams object\ndef dict_to_vcqgan_hparams(hparams_dict, dataset=None):\n    # Determine which hyperparameter class to use based on the dataset\n    if dataset == None:\n        dataset = hparams_dict.get('dataset', 'MNIST')  # Default to MNIST if not specified\n    \n    vq_hyper = HparamsVQGAN(dataset)\n    # Set attributes from the dictionary\n    for key, value in hparams_dict.items():\n        setattr(vq_hyper, key, value)\n    \n    return vq_hyper\n\n\ndef load_vqgan_from_checkpoint(H, vqgan):\n    vqgan = load_model(vqgan, \"vqgan\", H.load_step, H.load_dir).cuda()\n    vqgan.eval()\n    return vqgan\n\n\ndef encode_and_quantize(vqgan, terrain_chunks):\n    vqgan.eval()\n    with torch.no_grad():\n        encoded = vqgan.ae.encoder(terrain_chunks)\n        quantized, _, quant_stats = vqgan.ae.quantize(encoded)\n        print(f'zq shape: {quantized.size()}')\n        latent_indices = quant_stats[\"min_encoding_indices\"]\n        print(f'latent_indices size: {latent_indices.size()}')\n        latent_indices = latent_indices.view((encoded.size()[0], encoded.size()[2], encoded.size()[3]))\n        print(f'latent_indices viewed size: {latent_indices.size()}')\n\n    return quantized, latent_indices",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4250899b-6f26-475e-bb4f-3025bcf66ef9",
      "cell_type": "code",
      "source": "model_path = '../model_logs/minecraft39ch_ce_3'\nvqgan_hparams =  dict_to_vcqgan_hparams(load_hparams_from_json(f\"{model_path}\"), 'maps')\nvqgan = VQAutoEncoder(vqgan_hparams)\nvqgan = load_vqgan_from_checkpoint(vqgan_hparams, vqgan)\nprint(f'loaded from: {vqgan_hparams.log_dir}')\n# This takes a while\n\ntrain_loader= get_minecraft_dataloader(\n        '../datasets/minecraft_chunks.npy',\n        block_converter,\n        batch_size=vqgan_hparams.batch_size,\n        num_workers=0,\n    )\n\nall_blocks_index = []\nfor batch in train_loader:\n    batch_indices = torch.argmax(batch, dim=1)\n    all_blocks_index.append(batch_indices)\nall_blocks_index = torch.cat(all_blocks_index, dim=0) \n\n\nfrom sampler_utils import generate_latents_from_loader3d\nlatents = generate_latents_from_loader3d(vqgan_hparams, vqgan, train_loader)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf359f34-f13f-4105-b0fd-5e33e98f6d3a",
      "cell_type": "markdown",
      "source": "**extract all corresponding chunks from each code**",
      "metadata": {}
    },
    {
      "id": "1cb10796-8fd4-4528-a56b-a593e41cdea2",
      "cell_type": "code",
      "source": "latents.shape\n\ncode_chunks_dict = {i: [] for i in range(vqgan_hparams.codebook_size)}\n\nchunk_size = 4\nreshaped_latents = latents.view(-1, 6, 6, 6)\nN, D, H, W = reshaped_latents.shape\n\n# extract all corresponding chunks from each code. \nfor n in range(N):\n    for d in range(D):\n        for h in range(H):\n            for w in range(W):\n                code_idx = reshaped_latents[n, d, h, w].item()  # Get the code index\n                \n                # Compute the starting position in the block index tensor\n                d_start, h_start, w_start = d * chunk_size, h * chunk_size, w * chunk_size\n                \n                # Ensure indices do not exceed dimensions of all_blocks_index\n                if (d_start + chunk_size <= all_blocks_index.shape[1] and\n                    h_start + chunk_size <= all_blocks_index.shape[2] and\n                    w_start + chunk_size <= all_blocks_index.shape[3]):\n                    \n                    # Extract the 4x4x4 chunk from block indices\n                    block_chunk = all_blocks_index[n, \n                                                   d_start:d_start + chunk_size, \n                                                   h_start:h_start + chunk_size, \n                                                   w_start:w_start + chunk_size]\n                    \n                    # Store the extracted chunk in the corresponding code index entry\n                    code_chunks_dict[code_idx].append(block_chunk.cpu().numpy())\n\nprint(\"Code_chunks_dict is already finished. Now turn to have binary chunks...\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5525b19a-e98d-4938-8a05-fd75908aa94f",
      "cell_type": "markdown",
      "source": "**Convert into Binary Code**",
      "metadata": {}
    },
    {
      "id": "d0dc7b96-5e3b-4f0c-97e4-1f9d47879ce9",
      "cell_type": "code",
      "source": "def create_binary_chunk_code_dict (code_chunks_dict):\n    binary_code_chunks_dict = {i: [] for i in range(vqgan_hparams.codebook_size)}\n    for i in range(vqgan_hparams.codebook_size):\n        if code_chunks_dict[i]:\n            for chunk in code_chunks_dict[i]:\n                binary_chunk = []\n                for element in chunk:\n                    binary_chunk.append(np.where(element != 0, 1, 0).tolist())\n                binary_code_chunks_dict[i].append(binary_chunk)\n    print(\"Binary_code_chunks_dict is already finished. Now turn to have average_code_chunks_dict...\")\n    return binary_code_chunks_dict\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "279c56cb-538e-4f3e-a388-b885311d5fee",
      "cell_type": "markdown",
      "source": "**Calculate Entropy**",
      "metadata": {}
    },
    {
      "id": "d6bcee54-6cd8-412c-ab1f-03c461575e25",
      "cell_type": "code",
      "source": "def calculate_structural_score(binary_code_chunks_dict):\n    structural_score_value_dict = {i: [] for i in range(vqgan_hparams.codebook_size)}\n    for idx in range(vqgan_hparams.codebook_size):\n        if binary_code_chunks_dict[idx]:\n            array = np.array(binary_code_chunks_dict[idx])\n            num, d, h, w = array.shape\n            entropy_values = np.zeros((d,h,w))\n            for i in range(d):\n                for j in range(h):\n                    for k in range(w):\n                        values = array[:,i,j,k]\n                        p_1 = np.mean(values)\n                        p_0 = 1-p_1\n                        if p_1 == 0 or p_0 == 0:\n                            entropy_values[i,j,k] = 0.0\n                        else:\n                            entropy_values[i,j,k] = entropy([p_0,p_1],base = 2)\n\n\n            average_entropy = np.mean(entropy_values)\n            structural_score_value_dict[idx] = average_entropy\n        else:\n            structural_score_value_dict[idx] = None\n    print(\"Finish calculating structural scores...\")\n    return calculate_structural_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dc0b7268-3599-44a5-bd1e-8756ea213243",
      "cell_type": "markdown",
      "source": "**Draw Structural Heatmaps**\n",
      "metadata": {}
    },
    {
      "id": "656ed4a8-7320-4f51-ae39-52fb561067b2",
      "cell_type": "code",
      "source": "from matplotlib.colors import BoundaryNorm\n# create graph bar for heatmap\ncounter = 0\nlevels = [0, 0.2, 0.4, 0.6, 0.8, 1]\n#colors = ['#f0f0f0', '#d6d6d6', '#a3a3a3', '#636363', '#2c2c2c']\ncolors = ['#FFFFFF',  # White for 0-0.2\n          '#FFDD00',  # Bright Yellow for 0.2-0.4\n          '#FF6600',  # Bright Orange for 0.4-0.6\n          '#CC0000',  # Red for 0.6-0.8\n          '#2c2c2c']  # Black for 0.8-1.0\ncmap = mcolors.ListedColormap(colors)\nboundaries = levels\nnorm = BoundaryNorm(boundaries, cmap.N)\n\n# draw structural code heatmap\ndef print_structural_code_chunks_heatmap(score_value_dict, binary_code_chunks_dict):\n    for i in range(vqgan_hparams.codebook_size):\n        if score_value_dict[i] is not None and score_value_dict[i] < 0.5:\n            num, _, _, _ = np.array(binary_code_chunks_dict[i]).shape\n            freq_values = np.zeros((4,4,4), dtype = float)\n            '''\n            for chunk in binary_code_chunks_dict[i]:\n                freq_values += chunk\n            freq_values = freq_values/num\n            '''\n            chunks_array = np.array(binary_code_chunks_dict[i])\n            freq_values = np.mean(chunks_array, axis = 0)\n\n            #classified_freq = np.vectorize(get_color)(freq_values.flatten())\n\n            \n            x,y,z = np.indices((4,4,4))\n            x = x.flatten()\n            y = y.flatten()\n            z = z.flatten()\n            #freq_values = frequency.flatten()\n            #freq_values = np.full_like(x, frequency, dtype=float)\n            #print(f\"freq_values {i}: \", freq_values)\n            #freq_values = freq_values.flatten()\n            #freq_values = classified_freq.flatten()\n            #classified_freq = np.vectorize(get_color)(freq_values)\n            # print(\"freq_values: \", freq_values)\n            #normalized_freq = freq_values / np.max(freq_values)\n\n            #norm = mcolors.Normalize(vmin=np.min(freq_values), vmax = np.max(freq_values))\n            # print(\"Norm: \", norm)\n            fig = plt.figure(figsize = (8,8))\n            ax = fig.add_subplot(111,projection = '3d')\n            #cmap = plt.cm.hot_r\n            sc = ax.scatter(x,y,z,c=freq_values, cmap = cmap, norm = norm, s = 500, edgecolors = 'k')\n\n            cbar = plt.colorbar(sc, ax = ax, shrink = 0.5)\n            cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n            cbar.set_ticklabels(['0', '0.2', '0.4', '0.6', '0.8', '1.0']) \n            cbar.set_label(\"Frequency of 1s\")\n            ax.set_xlabel('X')\n            ax.set_ylabel(\"Y\")\n            ax.set_zlabel(\"Z\")\n            ax.set_title(f\"3D Frequency Heatmap of 1s in 4x4x4 Vectors (Index: {i}, Structural Score: {score_value_dict[i]})\")\n            filename = f\"heatmap_{i}.png\"\n            plt.savefig(filename, dpi=300)\n            print(f\"The heatmap of code index {i} is saved\")\n            plt.close(fig)\n            #counter += 1\n            #if(counter == 5):\n                #break",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e58f6f19-5e0a-423d-8103-98a045c6aa0b",
      "cell_type": "markdown",
      "source": "**Low Entropy Codes (High Structural Score)**",
      "metadata": {}
    },
    {
      "id": "de70501f-18d2-49d6-877a-9efca655ba50",
      "cell_type": "code",
      "source": "# find out all code indices with a score smaller than 0.5\ndef low_entropy_structural_codes(score_value_dict):\n    code_indices_with_low_entropy = []\n    for i in range(vqgan_hparams.codebook_size):\n        if score_value_dict[i] is not None and score_value_dict[i] < 0.5:\n            code_indices_with_low_entropy.append(i)\n    return code_indices_with_low_entropy",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e5f1081a-45dd-458d-b038-a9d6555026d5",
      "cell_type": "markdown",
      "source": "**Visualization Testing**",
      "metadata": {}
    },
    {
      "id": "bbf31b8a-42c2-4581-ab74-a397bc2cffdc",
      "cell_type": "code",
      "source": "import os\nfor code_idx in code_indices_with_low_entropy:\n    if code_chunks_dict[code_idx]:\n        num_chunks = len(code_chunks_dict[code_idx])\n        if num_chunks <= 20:\n            selected_indices = range(num_chunks)\n        else:\n            selected_indices = random.sample(range(num_chunks), 20)\n        save_dir = f'visualize_chunks_code_{code_idx}'\n        os.makedirs(save_dir, exist_ok = True)\n\n        for i, idx in enumerate(selected_indices):\n            first_chunk = code_chunks_dict[code_idx][idx]\n            if isinstance(first_chunk, torch.Tensor):\n                first_chunk = first_chunk.detach().cpu().numpy()\n\n            # convert to original ids\n            first_chunk_tensor = torch.tensor(first_chunk, dtype=torch.int64)\n            if first_chunk_tensor.dim() == 3:  # Shape: (4, 4, 4)\n                first_chunk_tensor = first_chunk_tensor.unsqueeze(0) \n            original_blocks = block_converter.convert_to_original_blocks(first_chunk_tensor)\n            original_blocks = original_blocks.squeeze(0).cpu().numpy()\n\n            # original_blocks = block_converter.convert_to_original_blocks(first_chunk)\n            # print(\"Original block chunks: \", original_blocks)\n\n\n            fig = visualize_chunk(\n                original_blocks, \n                figsize=(10, 10), \n                elev=20,  # Elevation angle for the 3D plot\n                azim=45   # Azimuth angle for the 3D plot\n            )\n            #routation\n            # first_chunk = first_chunk.transpose(2, 0, 1) # Moves axes from [D,H,W] to [W,D,H]\n            # first_chunk = np.rot90(first_chunk, 1, (0, 1))\n            # print(\"First chunk: \", first_chunk)\n\n\n\n\n            filename = os.path.join(save_dir, f\"visualized_chunk_code_{code_idx}_{idx}.png\")\n            fig.savefig(filename, dpi=300)\n            print(f\"Saved: {filename}\")\n            plt.close(fig)\n        print(f\"All visualizations saved in: {save_dir}\")\n    else:\n        print(f\"No chunks available for code index {code_idx}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0a090ce8-85ca-4d47-9a3b-08a59d3c2fff",
      "cell_type": "markdown",
      "source": "**Structural Dictionary**",
      "metadata": {}
    },
    {
      "id": "ec47a044-37ee-4178-a5b7-bd1693869b9e",
      "cell_type": "code",
      "source": "# a result dictionary where the first element is structural score and the second is the number of chunks\ndef get_strucutural_result(binary_code_chunks_dict, score_value_dict, code_indices_with_low_entropy):\n    structure_result_dict = {\n        code_idx: [float(score_value_dict[code_idx]), len(binary_code_chunks_dict[code_idx])]\n        for code_idx in code_indices_with_low_entropy\n        if code_idx in binary_code_chunks_dict and code_idx in score_value_dict\n    }\n    return structure_result_dict",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2f27cfb7-16a3-4d09-b03b-ab66ebba191c",
      "cell_type": "markdown",
      "source": "**Visualize Structural Histogram**",
      "metadata": {}
    },
    {
      "id": "48aa79bf-46fd-4cb5-980c-88048ef0ecd6",
      "cell_type": "code",
      "source": "sorted_items = sorted(structure_result_dict.items(), key=lambda x: x[1][1], reverse=True)\nsorted_indices = [item[0] for item in sorted_items]  # Sorted code indices by number of chunks\nsorted_scores = [item[1][0] for item in sorted_items]  # Corresponding structural scores\nsorted_chunk_counts = [item[1][1] for item in sorted_items]\n\nbar_width = 0.8\nx_positions = np.arange(len(sorted_indices))\nplt.figure(figsize=(18, 10))\nplt.bar(x_positions, sorted_scores, color='navy', alpha=0.9, edgecolor='black', linewidth = 0.6, width = bar_width)\nfor x, y, chunk_count in zip(x_positions, sorted_scores, sorted_chunk_counts):\n    plt.text(x, y + 0.02, str(chunk_count), ha='center', fontsize=10, fontweight='bold', rotation=90)\nplt.xlabel(\"Code Index (Sorted by Number of Chunks)\", fontsize = 12)\nplt.ylabel(\"Structural Score\", fontsize = 12)\nplt.title(\"Histogram of Structural Scores for VQGAN Codebook Entries\", fontsize = 14)\nplt.xticks(x_positions, sorted_indices, rotation=90, fontsize=10)\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.savefig(\"structural_scores_histogram.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "553bed52-945b-4530-b823-e9359e1e5855",
      "cell_type": "markdown",
      "source": "**Explore Style Information**",
      "metadata": {}
    },
    {
      "id": "e4d3aec3-8edd-4ef5-ae92-12b545167af9",
      "cell_type": "code",
      "source": "from collections import Counter\n# explore the style information\n# count the frequency of each type of blocks\ndef find_num_blocks():\n    num_blocks = {i: None for i in range(vqgan_hparams.codebook_size)}\n    for i, chunks in code_chunks_dict.items():\n        temp_dic = {a: 0 for a in range(39)}\n        total_num = 0\n        if code_chunks_dict[i]:\n            for chunk in code_chunks_dict[i]:\n                flattened_chunk = chunk.flatten()\n                block_count = Counter(flattened_chunk)\n                block_count = {int(k):v for k,v in block_count.items()}\n                for index, value in block_count.items():\n                    temp_dic[index] += value\n                    total_num += value\n        if total_num > 0:\n            for idx in temp_dic.keys():\n                temp_dic[idx] /= total_num\n        num_blocks[i] = temp_dic\n    return num_blocks  ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "c51292a5-7329-4acf-bbe6-06b5c71e8939",
      "cell_type": "markdown",
      "source": "**Calculate Style Score**",
      "metadata": {}
    },
    {
      "id": "014d6419-088e-43de-b843-16eb04609925",
      "cell_type": "code",
      "source": "# calculate the style score based on \ndef calculate_style_score(): \n    style_scores = {}\n    for i in range(39):\n        style_scores[i] = 0\n    block_counters = []\n    final_style_score = {i: 0 for i in range(vqgan_hparams.codebook_size)}\n    for i, chunks in code_chunks_dict.items():\n    # for i in range(512):\n        single_score = 0\n        if code_chunks_dict[i]:\n            chunk_scores = []\n            for chunk in code_chunks_dict[i]:\n                flattened_chunk = chunk.flatten()\n                block_count = Counter(flattened_chunk)\n                block_count = {int(k):v for k,v in block_count.items()}\n\n                style_scores = {i: 0 for i in range(39)}  \n                for key in block_count.keys():\n                    style_scores[key] = block_count[key]\n\n                # print(\"Block_count: \", block_count)\n                \n                # fi = list(block_count.values())\n                fi = list(style_scores.values())\n                max_F = max(fi)\n                # num_F = len(fi)\n                total_types_of_blocks = 39\n\n                # if len(fi) == 1:\n                #    style_score = ((max_F ** 2)/num_F) ** 0.5\n                #else:\n                #    style_score = (sum((max_F - f)**2 for f in fi)/num_F)** 0.5\n                style_score =  (sum((max_F - f) **2 for f in fi)/(total_types_of_blocks - 1)) ** 0.5\n                single_score += style_score\n\n                #chunk_scores.append(style_score)\n                #block_counters.append([block_count, style_score])\n            # print(\"Chunk_scores: \", chunk_scores)\n            #sorted_block_counters = sorted(block_counters, key = lambda x: x[1])\n            single_score = single_score / len(code_chunks_dict[i])\n            final_style_score[i] = single_score\n            #print(\"Score: \", single_score)\n            #break\n    return final_style_score\n\ndef find_high_style_codes(final_style_score):\n    high_style_score_code_index = {}\n    for i in final_style_score.keys():\n        if final_style_score[i] > 45:\n            high_style_score_code_index[i] = [final_style_score[i], len(code_chunks_dict[i])]\n    sorted_high_style_score_code_index = dict(sorted(\n        high_style_score_code_index.items(),\n        key=lambda x: x[1][1],  # Sort by len(code_chunks_dict[i]), which is stored at index 1\n        reverse=True  # Optional: Sort in descending order\n    ))\n    return sorted_high_style_score_code_index\n# print(\"High Style Score Codes: \", high_style_score_code_index)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a8f815c-3f6c-46ad-b1fd-c984574e891d",
      "cell_type": "markdown",
      "source": "**Visualize Style Chunks**",
      "metadata": {}
    },
    {
      "id": "b88f4cca-6290-4952-b7c4-c756e51ddcea",
      "cell_type": "code",
      "source": "def print_style_code_chunks(sorted_high_style_score_code_index, code_chunks_dict):\n    import os\n    # print(\"Converted block chunks: \", code_chunks_dict[code_idx][0])\n    for code_idx in sorted_high_style_score_code_index.keys():\n        if code_chunks_dict[code_idx]:\n            num_chunks = len(code_chunks_dict[code_idx])\n            if num_chunks <= 10:\n                selected_indices = range(num_chunks)\n            else:\n                selected_indices = random.sample(range(num_chunks), 10)\n            save_dir = f'visualize_chunks_code_{code_idx}'\n            os.makedirs(save_dir, exist_ok = True)\n\n            for i, idx in enumerate(selected_indices):\n                first_chunk = code_chunks_dict[code_idx][idx]\n                if isinstance(first_chunk, torch.Tensor):\n                    first_chunk = first_chunk.detach().cpu().numpy()\n\n                # convert to original ids\n                first_chunk_tensor = torch.tensor(first_chunk, dtype=torch.int64)\n                if first_chunk_tensor.dim() == 3:  # Shape: (4, 4, 4)\n                    first_chunk_tensor = first_chunk_tensor.unsqueeze(0) \n                original_blocks = block_converter.convert_to_original_blocks(first_chunk_tensor)\n                original_blocks = original_blocks.squeeze(0).cpu().numpy()\n\n                # original_blocks = block_converter.convert_to_original_blocks(first_chunk)\n                # print(\"Original block chunks: \", original_blocks)\n\n\n                fig = visualize_chunk(\n                    original_blocks, \n                    figsize=(10, 10), \n                    elev=20,  # Elevation angle for the 3D plot\n                    azim=45   # Azimuth angle for the 3D plot\n                )\n                #routation\n                # first_chunk = first_chunk.transpose(2, 0, 1) # Moves axes from [D,H,W] to [W,D,H]\n                # first_chunk = np.rot90(first_chunk, 1, (0, 1))\n                # print(\"First chunk: \", first_chunk)\n\n                filename = os.path.join(save_dir, f\"visualized_chunk_code_{code_idx}_{idx}.png\")\n                fig.savefig(filename, dpi=300)\n                print(f\"Saved: {filename}\")\n                plt.close(fig)\n            print(f\"All visualizations saved in: {save_dir}\")\n        else:\n            print(f\"No chunks available for code index {code_idx}\")\n\n\ndef plot_style_histogram(sorted_high_style_score_code_index):\n    sorted_indices = list(sorted_high_style_score_code_index.keys())\n    sorted_scores = [val[0] for val in sorted_high_style_score_code_index.values()]\n    sorted_chunk_counts = [val[1] for val in sorted_high_style_score_code_index.values()]\n\n    bar_width = 1.5\n    x_positions = np.arange(len(sorted_indices))\n    plt.figure(figsize=(60, 20))\n    plt.bar(x_positions, sorted_scores, color='navy', alpha=0.9, edgecolor='black', linewidth = 0.6, width = bar_width)\n    for x, y, chunk_count in zip(x_positions, sorted_scores, sorted_chunk_counts):\n        plt.text(x, y + 2.5, str(chunk_count), ha='center', fontsize=16, fontweight='bold', rotation=90)\n    plt.xlabel(\"Code Index (Sorted by Number of Chunks)\", fontsize = 20)\n    plt.ylabel(\"Style Score\", fontsize = 20)\n    plt.title(\"Histogram of Style Scores for VQGAN Codebook Entries\", fontsize = 22)\n    plt.xticks(x_positions, sorted_indices, rotation=90, fontsize=16)\n    plt.grid(axis='y', linestyle='--', alpha=0.6)\n    plt.savefig(\"style_scores_histogram.png\", dpi=300, bbox_inches=\"tight\")\n    plt.close() ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "id": "f14745ae-99d9-4140-9466-a239aab2f727",
      "cell_type": "markdown",
      "source": "**Find Most Common Block Types**",
      "metadata": {}
    },
    {
      "id": "e62d71cf-0e4f-4790-a6f8-4a2ee0546fdd",
      "cell_type": "code",
      "source": "blocks_to_types = {\n    0: \"air\",\n    1: \"None\", 2: \"None\", 3: \"cacutus\", 4: \"None\", 5: \"clay\", 6: \"coal ore\", 7: \"None\", 8: \"None\", 9: \"dirt\", 10: \"double plant\", 11: \"None\", 12: \"None\", 13: \"gold ore\", 14: \"grass\", 15: \"gravel\", 16: \"iron ore\", 17: \"None\", 18: \"leaves\", 19: \"leaves\", 20: \"log1\", 21: \"log2\", 22: \"None\", 23: \"None\", 24: \"None\", 25: \"pumpkin stem\", 26: \"red flower\", 27: \"None\", 28: \"None\", 29: \"sand\", 30: \"sandstone\", 31: \"None\", 32: \"stone\", 33: \"None\", 34: \"tall grass\", 35: \"vine\", 36: \"water\", 37: \"None\", 38: \"yellow flower\"\n}\n\ndef find_most_common_block_types(sorted_high_style_score_code_index, code_chunks_dict):\n    total_block_counter = {}\n    for code_idx in sorted_high_style_score_code_index.keys():\n        code_block_count = Counter()\n        total_number_of_blocks = 0\n        for chunk in code_chunks_dict[code_idx]:\n            flattened_chunk = chunk.flatten()\n            chunk_block_count = Counter(flattened_chunk)\n            chunk_block_count = {int(k): v for k, v in chunk_block_count.items()}\n            total_number_of_blocks += sum(chunk_block_count.values())\n            code_block_count.update(chunk_block_count)\n        if total_number_of_blocks > 0:\n            code_block_percentage = {k: v / total_number_of_blocks for k, v in code_block_count.items()}\n            code_block_percentage = dict(sorted(code_block_percentage.items(), key=lambda item: item[1], reverse=True))\n        # code_block_count = dict(sorted(code_block_count.items(), key = lambda item: item[1], reverse = True))\n        total_block_counter[code_idx] = code_block_percentage\n    return total_block_counter\n\ndef print_most_common_type_and_frequency(total_block_counter):\n    for key, sub_dict in total_block_counter.items():\n        top_3_items = sorted(sub_dict.items(), key=lambda item: item[1], reverse=True)[:3]\n        print(f\"Code index: {key}\")\n        for sub_key, value in top_3_items:\n            if sub_key in blocks_to_types.keys():\n                print(f\"{sub_key} ({blocks_to_types[sub_key]}): {value}\")\n            else:\n                print(f\"{sub_key}: {value}\")\n        print()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e86ca0e0-df3f-4fdb-afa3-3eece441afd2",
      "cell_type": "markdown",
      "source": "**Visualization of Blocks Types in Histogram**",
      "metadata": {}
    },
    {
      "id": "42c58e64-5ffc-4257-90c2-6bca852c2b3a",
      "cell_type": "code",
      "source": "def block_freq_histogram(blocks_to_code_indices, num_blocks):\n    os.makedirs('Block_Freq_Histogram', exist_ok=True)\n    for block_id, code_indices in blocks_to_code_indices.items():\n        if not code_indices:  # Skip if no code indices for this block\n            continue\n        block_name = blocks_to_types.get(block_id, f\"Unknown\")\n        frequencies = [num_blocks[code_index][block_id] for code_index in code_indices]\n        plt.figure(figsize=(12, 6))\n        plt.bar(code_indices, frequencies, color='skyblue', edgecolor='black')\n        plt.xlabel('Code Index', fontsize=12)\n        plt.ylabel('Frequency', fontsize=12)\n        plt.xticks(ticks=range(len(code_indices)), labels=code_indices, rotation=90, fontsize=8)\n        plt.title(f'Histogram of Block {block_id}: \"{block_name}\" Frequencies Across Code Indices', fontsize=14)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n\n        # Save the plot\n        filename = f'Block_Freq_Histogram/block_{block_id}_{block_name}.png'\n        plt.tight_layout()\n        plt.savefig(filename, dpi=300, bbox_inches='tight')\n        plt.close()\n        print(f'Histogram saved for block \"{block_name}\" (Block ID: {block_id}).')\n\n\n\n\ndef block_type_histogram(total_block_counter):\n    os.makedirs(\"Block_Type_Histogram\", exist_ok = True)\n    for code_idx, block_freq in total_block_counter.items():\n        filtered_blocks = {block_id: freq for block_id, freq in block_freq.items() if freq > 0}\n        if not filtered_blocks:\n            continue\n        block_names = [blocks_to_types.get(block_id, f\"Unknown({block_id})\") for block_id in filtered_blocks.keys()]\n        frequencies = list(filtered_blocks.values())\n        plt.figure(figsize=(12, 6))\n        plt.bar(block_names, frequencies, color='skyblue', edgecolor='black')\n        plt.xlabel('Block Type', fontsize=12)\n        plt.ylabel('Frequency', fontsize=12)\n        plt.title(f'Block Types Histogram for Code Index {code_idx}', fontsize=14)\n\n\n        # Add grid for better readability\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n\n        # Save the plot to the directory\n        filename = f'Block_Type_Histogram/code_index_{code_idx}.png'\n        plt.tight_layout()\n        plt.savefig(filename, dpi=300, bbox_inches='tight')\n        plt.close()\n\n        print(f'Histogram saved for code index {code_idx}.')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5a8d5ab8-c463-4a3e-8c90-1b5ed7117496",
      "cell_type": "markdown",
      "source": "**Find The Max Frequency Block of Each Code**",
      "metadata": {}
    },
    {
      "id": "c14d9b0a-5012-4a45-a1fe-5c0e8bcffda0",
      "cell_type": "code",
      "source": "def find_max_frequency_code_index(num_blocks):\n    # Initialize the dictionary to store the code index with the highest frequency for each block ID\n    blocks_to_code_indices = {block_id: [] for block_id in range(39)}\n    for code_index, block_freqs in num_blocks.items():\n        if block_freqs:\n            bid = None\n            freq = None\n            # Find the maximum frequency for the current code index\n            for id, f in block_freqs.items():\n                if bid is None:\n                    bid = id\n                    freq = f \n                else:\n                    if f > freq:\n                        bid = id\n                        freq = f\n            blocks_to_code_indices[bid].append(code_index)\n    return blocks_to_code_indices\n\n\n\nfinal_style_score = calculate_style_score()\nsorted_high_style_score_code_index = find_high_style_codes(final_style_score)\nnum_blocks = find_num_blocks()\nblocks_to_code_indices = find_max_frequency_code_index(num_blocks)\ntotal_block_counter = find_most_common_block_types(sorted_high_style_score_code_index, code_chunks_dict)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "20e68583-15c0-417c-98f8-58979134923c",
      "cell_type": "markdown",
      "source": "**Explore Spatial Relationship**",
      "metadata": {}
    },
    {
      "id": "9111217f-ac88-439e-9271-c1fbb4b35b1e",
      "cell_type": "code",
      "source": "def find_the_spatial_relation(reshaped_latents):\n    N, D, H, W = reshaped_latents.shape\n    code_spatial_frequency = {i: np.zeros((6,6,6), dtype = int) for i in range (vqgan_hparams.codebook_size)}\n    for n in range(N):\n        for d in range(D):\n            for h in range(H):\n                for w in range(W):\n                    code_idx = reshaped_latents[n, d, h, w].item()\n                    code_spatial_frequency[code_idx][d,h,w] += 1\n    return code_spatial_frequency\n\nos.makedirs('Spatial_Heatmaps', exist_ok=True)\ndef plot_spatial_frequency(code_spatial_frequency):\n    for code_index, count_array in code_spatial_frequency.items():\n        total_num_chunks = np.sum(count_array)\n        freq_values = count_array / total_num_chunks if total_num_chunks > 0 else count_array\n        x,y,z = np.indices((6,6,6))\n        x,y,z = x.flatten(), y.flatten(), z.flatten()\n        freq_values_flat = freq_values.flatten()\n\n        fig = plt.figure(figsize = (10,10))\n        ax = fig.add_subplot(111,projection = '3d')\n        #cmap = plt.cm.hot_r\n        sc = ax.scatter(x,y,z,c=freq_values_flat, cmap = cmap, norm = norm, s = 500, edgecolors = 'k')\n\n\n        cbar = plt.colorbar(sc, ax = ax, shrink = 0.5)\n        cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n        cbar.set_ticklabels(['0', '0.2', '0.4', '0.6', '0.8', '1.0']) \n        cbar.set_label(\"Frequency in Each Position\")\n        ax.set_xlabel('X')\n        ax.set_ylabel(\"Y\")\n        ax.set_zlabel(\"Z\")\n        ax.set_title(f\"3D Heatmap of Frequency in Each Position (Index: {code_index}). Total Number of Chunks: {total_num_chunks}\")\n        filename = f\"Spatial_Heatmaps/spatial_heatmap_{code_index}.png\"\n        plt.savefig(filename, dpi=300)\n        print(f\"The spatial heatmap of code index {code_index} is saved\")\n        plt.close(fig)\n        \ndef find_spatial_dominance(code_spatial_frequency):\n    code_spatial_dominance = {i: 0 for i in range (vqgan_hparams.codebook_size)}\n    for code_index, count_array in code_spatial_frequency.items():\n        total_num_chunks = np.sum(count_array)\n        freq_values = np.max(count_array / total_num_chunks) if total_num_chunks > 0 else 0\n        code_spatial_dominance[code_index] = [freq_values, total_num_chunks]\n    return code_spatial_dominance",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "436a6334-e5e0-41ad-bec0-ec50138fea5b",
      "cell_type": "markdown",
      "source": "**Plot Spatial Heatmaps**",
      "metadata": {}
    },
    {
      "id": "41bd95c3-b6d0-49b1-882b-72673e8b7cfd",
      "cell_type": "code",
      "source": "def plot_spatial_dominance_histogram(code_spatial_dominance):\n    # Extract code indices, maximum frequencies, and total chunk counts\n    code_indices = list(code_spatial_dominance.keys())\n    freq_values = [code_spatial_dominance[i][0] for i in code_indices]\n    total_num_chunks = [code_spatial_dominance[i][1] for i in code_indices]\n\n    # Combine data and sort by total_num_chunks in descending order\n    combined_data = list(zip(code_indices, freq_values, total_num_chunks))\n    sorted_data = sorted(combined_data, key=lambda x: x[2], reverse=True)  # Sort by total_num_chunks\n    sorted_data = [entry for entry in sorted_data if entry[2] > 10]\n    # Unzip sorted data\n    sorted_code_indices, sorted_freq_values, sorted_total_num_chunks = zip(*sorted_data)\n\n    # Plotting the histogram\n    plt.figure(figsize=(30, 10))\n    plt.bar(range(len(sorted_code_indices)), sorted_freq_values, color='skyblue', edgecolor='black', width=0.6)\n\n    plt.xticks(ticks=np.arange(len(sorted_code_indices)),  # Positions of the bars\n               labels=sorted_code_indices,  # Actual code indices as labels\n               rotation=90, fontsize=8)\n    # Axis labels and title\n    plt.xlabel('Code Index (Sorted by Total Chunks)', fontsize=12)\n    plt.ylabel('Maximum Frequency', fontsize=12)\n    plt.title('Histogram of Maximum Frequency per Code Index (Sorted by Total Chunks)', fontsize=14)\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n\n    # Display the plot\n    plt.tight_layout()\n    plt.savefig(\"spatial_histogram.png\", dpi=300, bbox_inches=\"tight\")\n    plt.close\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b7e266f6-927f-48b7-bed7-34d8692de1ad",
      "cell_type": "markdown",
      "source": "**Block ids to Original Block Types**",
      "metadata": {}
    },
    {
      "id": "41b7bd6d-2af7-4b1a-93c8-0da1bd56becc",
      "cell_type": "code",
      "source": "block_converter_to_original = {}\n# block_converter_to_original.keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\noriginal_block_ids = [5, 26, 27, 29, 35, 38, 40, 41, 56, 60, 62, 83, 84, 92, 93, 95, 108, 118, 119, 120, 131, 132, 138, 139, 140, 166, 184, 187, 192, 194, 195, 204, 217, 222, 227, 237, 240, 241, 251]\nfor i in range(39):\n    block_converter_to_original[i] = original_block_ids[i]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "048e96f7-e71c-4fd9-a925-ad6e6946a2fb",
      "cell_type": "markdown",
      "source": "**Block Frequency Dictionary**",
      "metadata": {}
    },
    {
      "id": "4764c7b4-3318-48c1-b42c-99fca7d2a3b6",
      "cell_type": "code",
      "source": "#find the percentage frequency of each block type for a specific code.\ndef find_blocks_frequency(code_chunks_dict):\n    total_block_counter = {}\n    for code_idx in range(vqgan_hparams.codebook_size):\n        code_block_count = Counter()\n        total_number_of_blocks = 0\n        for chunk in code_chunks_dict[code_idx]:\n            flattened_chunk = chunk.flatten()\n            chunk_block_count = Counter(flattened_chunk)\n            chunk_block_count = {int(k): v for k, v in chunk_block_count.items()}\n            total_number_of_blocks += sum(chunk_block_count.values())\n            code_block_count.update(chunk_block_count)\n        if total_number_of_blocks > 0:\n            code_block_percentage = {k: v / total_number_of_blocks for k, v in code_block_count.items()}\n            code_block_percentage = dict(sorted(code_block_percentage.items(), key=lambda item: item[1], reverse=True))\n        # code_block_count = dict(sorted(code_block_count.items(), key = lambda item: item[1], reverse = True))\n            total_block_counter[code_idx] = code_block_percentage\n        else:\n            total_block_counter[code_idx] = None\n    return total_block_counter",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "64f87604-b02f-4d0a-bf2b-27c41542a7e6",
      "cell_type": "markdown",
      "source": "**Identify Specific Biome**",
      "metadata": {}
    },
    {
      "id": "750f5abf-944e-402a-b085-3ec47d6e6faa",
      "cell_type": "code",
      "source": "# without requiring key to have the max frequency\n# For a code, if it's corresponding chunk includes block types in the following category,\n# then it is likely that the chunk represents this biome.\ndef find_styles(temp_arr):\n    most_common_5_block_types = []\n    for i in temp_arr:\n        most_common_5_block_types.append(i[0])\n    desert = [29, 194, 195] # key = 194 sand\n    ocean = [240, 194, 60, 95] # key = 240 water\n    grass_land = [10, 60, 93, 119, 120, 217, 227, 237, 60, 131, 132, 95, 243, 197, 166, 167, 184, 250, 251]\n    # key = 60 dirt\n    ore = [10, 92, 217, 40, 108, 95, 195] # key = 217 stone\n    result = []\n    # desert\n    if 194 in most_common_5_block_types:\n        common_blocks = len([elements for elements in most_common_5_block_types if elements in desert])\n        if len(most_common_5_block_types) == 1:\n            result.append(\"desert\")\n        elif common_blocks >= 2 and \"desert\" not in result:\n            result.append(\"desert\")\n    # ocean\n    if 240 in most_common_5_block_types:\n        common_blocks = len([elements for elements in most_common_5_block_types if elements in ocean])\n        if len(most_common_5_block_types) == 1:\n            result.append(\"ocean\")\n        elif common_blocks >= 2 and \"ocean\" not in result:\n            result.append(\"ocean\")\n    # grass_land\n    if 60 in most_common_5_block_types:\n        common_blocks = len([elements for elements in most_common_5_block_types if elements in ocean])\n        if len(most_common_5_block_types) == 1:\n            result.append(\"grass_land\")\n        elif common_blocks >= 2 and \"grass_land\" not in result:\n            result.append(\"grass_land\")\n    # ore\n    if 217 in most_common_5_block_types:\n        common_blocks = len([elements for elements in most_common_5_block_types if elements in ore])\n        if len(most_common_5_block_types) == 1:\n            result.append(\"ore\")\n        elif common_blocks >= 2 and \"ore\" not in result:\n            result.append(\"ore\")\n    return result\n\n\ndef find_five_most_common_block_types(total_block_counter):\n    dict1 = {}\n    for key, sub_dict in total_block_counter.items():\n        if sub_dict is not None:\n            sub_dict[0] = 0\n            sorted_blocks = sorted(sub_dict.items(), key=lambda item: item[1], reverse=True)[:5]\n            dict1[key] = sorted_blocks\n        else:\n            dict1[key] = None\n    return dict1\n\n#print out the corresponding biome information.\nimport copy\n\nblock_frequency = find_blocks_frequency(code_chunks_dict)\ntop_5_items = find_five_most_common_block_types(block_frequency)\n\nwith open('Style_Information.txt', 'w') as file:\n    for i in top_5_items.keys():\n        if top_5_items[i] is not None:\n            temp = copy.deepcopy(top_5_items[i])\n            for j in range(len(temp)):\n                temp[j] = list(temp[j])\n                temp[j][0] = block_converter_to_original[temp[j][0]]\n            result = find_styles(temp)\n            file.write(f\"Code idx {i}: {result} \\n\\n\")\n\n            temp2 = copy.deepcopy(top_5_items[i])\n            for j in range(len(temp2)):\n                temp2[j] = list(temp2[j])\n                temp2[j][0] = blocks_to_types[temp2[j][0]]\n            file.write(f\"Frequencies = {temp2} \\n\\n\")\n            file.write(f\"Length = {len(code_chunks_dict[i])} \\n\\n\")\n        else:\n            file.write(f\"Code idx {i}: None \\n\\n\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}